---
title: "PS1 No.1A Rebecca"
author: "Rebecca"
date: ""
output:
  html_document:
    df_print: paged
  df_print: kable
  pdf_document:
    keep_tex: yes
toc: no
---

```{r setup, include=FALSE}
library(tidyverse)
library(FE)
library(psych)
library(knitr)
library(xtable)

daily <- DJ_d$r_Dow_Jones
weekly <- DJ_w$r_close
```

## Statistical Properties of Asset Returns
### Distributional properties of Dow Jones index returns
> 1)

The Dow Jones is a stock market index of 30 prominent companies listed on stock exchanges in the United States and one of the oldest and most commonly followed equity indexes. Due to several beneficial properties such as symmetry and time-additivity and the fact that they can be interpreted as continuously compunded returns, logarithmic returns of the Dow Jones are considered here. When plotted over time in Figure ???, the time series of daily log returns appears at first sight to be more stationary than non-stationary. One remarkable feature of the series is the larger variance between 1928-1940. This can probably be explained by the financial crisis that started in 1928 and after that, by the beginning of World War II. The same pattern can naturally also be observed for the weekly log returns (see Appendix).

```{r plot1A1.1, echo=F}
plot1A1.1 <- ggplot(data=DJ_d) + geom_line(aes(x=1:nrow(DJ_d), y=r_Dow_Jones)) +
  labs(x='Time horizon', y='Log return', title='Dow Jones daily log returns')
plot1A1.1 + theme_classic()
```

Table ??? summarizes the distributional parameters of both the daily and weekly compounded returns of the Dow Jones between 1900-1990. The Dow Jones log returns seem to have a mean close to zero but slightly positive for both weekly and daily data. The distribution of returns is moderately (daily data) to highly (weekly data) negatively skewed. It also shows a remarkably high degree of kurtosis, around 36.6 for daily data and 15.06 for weekly data. 

#### Table of distributional parameters
```{r distrib prop, echo=F}
distr_daily <- data.frame(describe(DJ_d$r_Dow_Jones), row.names = "Daily")
distr_weekly <- data.frame(describe(DJ_w$r_close), row.names = "Weekly")

dat.df <- t(rbind.data.frame(distr_daily, distr_weekly))
kable(dat.df[c("n", "mean", "sd", "median", "min", "max", "skew", "kurtosis"), ])
```
Overall, the daily and weekly data appear to be comparable in range and mean but depict highly different degrees of skewness and kurtosis, indicating that the daily log returns are portrayed by a less negatively skewed distribution with a much higher kurtosis.


> 2)

```{r qq normal, echo=F}
#daily
std_daily = (daily - mean(daily))/sd(daily) # standardize the daily return to st.norm distrib.
qqnorm(std_daily, main = "Normal Q-Q plot for daily log returns")
qqline(std_daily, col = "red")

#weekly
std_weekly = (weekly - mean(weekly))/sd(weekly)
qqnorm(std_weekly, main = "Normal Q-Q plot for weekly log returns")
qqline(std_weekly, col = "red")
```

```{r qq t daily, echo=F}
#daily
df = 3 # the lower the df the bigger the kurtosis
std_daily_t = std_daily*sqrt(df/(df-2))
qqplot(rt(length(std_daily_t), df = df), std_daily_t, ,  main = "T-distribution Q-Q plot for daily log returns", xlab = "Theoretical Quantiles", ylab = "Sample Quantiles")
qqline(std_daily_t, col = "red")
```

```{r qq t weekly, echo=F}
#weekly
df=3 #because we need two parameters to normalize the data (mean and std dev)
std_daily = (daily - mean(daily))/sd(daily)
std_weekly = (weekly - mean(weekly))/sd(weekly)
std_daily_t = std_daily*sqrt(df/(df-2))

std_weekly_t = std_weekly*sqrt(df/(df-2))
qqplot(rt(length(std_weekly_t), df = df), std_weekly_t,  main = "T-distribution Q-Q plot for weekly log returns", xlab = "Theoretical Quantiles", ylab = "Sample Quantiles")
qqline(std_weekly_t, col = "red")
```

When plotted against the theoretical quantiles of the normal distribution, Figure ??? provides graphical evidence against the normal distribution being the true underlying distribution of daily and weekly log returns. The slightly S-shaped tails of the quantiles point towards a distribution with a higher kurtosis which is in line with the distributional parameters discussed above. The T-distribution seems to offer a slightly better fit, especially in the case of daily returns. But considering the scattering of the quantiles around the qqline(???) at the edges, the true distribution indicates a lower kurtosis than the T-distribution. Neither the normal distribution nor the T-distribution seem to provide good enough fits for daily and weekly log returns of the Dow Jones.

> 3)

```{r test normal, echo=F}

test_tab <- matrix(nrow=2, ncol=3)
rownames(test_tab) <- c('Daily', 'Weekly')
colnames(test_tab) <- c('Normal', 'Student t (df=4)', 'Mixed normal')

test_tab.p <- matrix(nrow=2, ncol=3)
rownames(test_tab.p) <- c('Daily', 'Weekly')
colnames(test_tab.p) <- c('Normal', 'Student t (df=4)', 'Mixed normal')

b = 30
bin = 1:b/b

#daily
r_nor = pnorm(std_daily)
#hist(r_nor, breaks = 50)

vn = NULL
for(val in bin) vn = c(vn,sum(r_nor <= val)) 
vn = c(vn[1],diff(vn))
chi_test = sum((vn-length(std_daily)/b)**2/(length(std_daily)/b))
cat("test =",chi_test," df =",b-3," p-value =",1-pchisq(chi_test,df=b-3))

test_tab[1, 1] <- chi_test
test_tab.p[1, 1] <- 1-pchisq(chi_test,df=b-3)

#weekly
r_nor_w = pnorm(std_weekly)
#hist(r_nor_w, breaks=50)

vn_w = NULL
for(val in bin) vn_w = c(vn_w,sum(r_nor_w <= val)) #try to compute the frequency for the bins
vn_w = c(vn_w[1],diff(vn_w)) # put 1st value because differencing (why?) loses the first observation; vector of probabilities?
chi_test_w = sum((vn_w-length(std_daily)/b)**2/(length(std_weekly)/b))
cat("test =",chi_test_w," df =",b-3," p-value =",1-pchisq(chi_test_w,df=b-3))

test_tab[2, 1] <- chi_test_w
test_tab.p[2, 1] <- 1-pchisq(chi_test_w,df=b-3)
```

```{r test t, echo=F}
df = 4

#daily
r_t = pt(std_daily_t,df=df)
#hist(r_t, breaks=50)
vt = NULL; for(val in bin) vt = c(vt,sum(vt <= val))
vt = c(vt[1],diff(vt))
test = sum((vt-length(std_daily_t)/b)**2/(length(std_daily_t)/b)) # he used the std. normal data, not for t-dist.
cat("test =",test," df =",b-3," p-value =",1-pchisq(test,df=b-3)) # p-value = 0, reject t distr.
#diff. output than his (df, test etc)
test_tab[1, 2] <- test
test_tab.p[1, 2] <- 1-pchisq(test,df=b-3)

#weekly
r_t_w = pt(std_weekly_t,df=df)
#hist(r_t_w, breaks=50)
vt_w = NULL; for(val in bin) vt_w = c(vt_w,sum(vt_w <= val))
vt_w = c(vt[1],diff(vt_w))
test = sum((vt_w-length(std_weekly_t)/b)**2/(length(std_weekly_t)/b))
cat("test =",test," df =",b-3," p-value =",1-pchisq(test,df=b-3))

test_tab[2, 2] <- test
test_tab.p[2, 2] <- 1-pchisq(test,df=b-3)

```

```{r test mix, echo=F}

#arbitrary choice
alpha = 0.4
sigma = 2.7 # this is the var of the second normal distr. and the first one is std_daily?

#daily
mix_daily = std_daily*sqrt((1-alpha) + alpha*sigma**2) #as data is std. and needs to be multiplied with var of mixed distr.
r_mix = (1-alpha)*pnorm(mix_daily) + alpha*pnorm(mix_daily,sd=sigma) #corresp. CDF of the mixture normal distr.
#hist(r_mix)
vn_mix = NULL; for(val in bin) vn_mix = c(vn_mix,sum(r_mix <= val))
vn_mix = c(vn_mix[1],diff(vn_mix))
test = sum((vn_mix-length(std_daily)/b)**2/(length(std_daily)/b))
cat("test =",test," df =",b-3," p-value =",1-pchisq(test,df=b-3))

test_tab[1, 3] <- test
test_tab.p[1, 3] <- 1-pchisq(test,df=b-3)

#weekly
mix_weekly = std_weekly*sqrt((1-alpha) + alpha*sigma**2) #as data is std. and needs to be multiplied with var of mixed distr.
r_mix_w = (1-alpha)*pnorm(mix_weekly) + alpha*pnorm(mix_weekly,sd=sigma) #corresp. CDF of the mixture normal distr.
#hist(r_mix)
vn_mix_w = NULL; for(val in bin) vn_mix_w = c(vn_mix_w,sum(r_mix_w <= val))
vn_mix_w = c(vn_mix_w[1],diff(vn_mix_w))
test = sum((vn_mix_w-length(std_weekly)/b)**2/(length(std_weekly)/b))
cat("test =",test," df =",b-3," p-value =",1-pchisq(test,df=b-3))

test_tab[2, 3] <- test
test_tab.p[2, 3] <- 1-pchisq(test,df=b-3)

print(xtable(test_tab, caption = 'Test statistic'), caption.placement = 'top')
print(xtable(test_tab.p, caption = 'P-values'), caption.placement = 'top')
```
This result is further supported by a $\chi^2$-goodness-of-fit test against both distributions. As the p-values reported in Table ??? show, the hypothesis of either the t-distribution or the normal distribution as the true underlying distribution of daily and/or weekly log returns is rejected at the highest significance level. Also when assuming a two-component mixed normal distribution consisting of the standardized normal distribution and one with $\alpha = 0.4$ $\sigma = 2.7$, this result doesn't change, even though the test statistic becomes much smaller (see Table ???). 
```{r optimize mix, echo=F}
#optimization daily
func <- function(vx){
  alpha = vx[1]
  sigma = vx[2]
  mix_daily_opt = std_daily*sqrt((1-alpha) + alpha*sigma**2)

  r_mix_opt = (1-alpha)*pnorm(mix_daily_opt) + alpha*pnorm(mix_daily_opt,sd=sigma)
  vn_mix_opt = NULL; for(val in bin) vn_mix_opt = c(vn_mix_opt,sum(r_mix_opt <= val))
  vn_mix_opt = c(vn_mix_opt[1],diff(vn_mix_opt))
  return(sum((vn_mix_opt-length(std_daily)/b)**2/(length(std_daily)/b)))
}

func(c(0.15,4))

res <- suppressWarnings(optim(par=c(0.1,4),fn=func,method="BFGS")) # this is not cherry-picking, this is optimizing (similar to OLS)

res
1-pchisq(res$value,df=b-3)

#optimization weekly
func <- function(vx){
  alpha = vx[1]
  sigma = vx[2]
  mix_weekly_opt = std_weekly*sqrt((1-alpha) + alpha*sigma**2)

  r_mix_opt_w = (1-alpha)*pnorm(mix_weekly_opt) + alpha*pnorm(mix_weekly_opt,sd=sigma)
  vn_mix_opt_w = NULL; for(val in bin) vn_mix_opt_w = c(vn_mix_opt_w,sum(r_mix_opt_w <= val))
  vn_mix_opt_w = c(vn_mix_opt_w[1],diff(vn_mix_opt_w))
  return(sum((vn_mix_opt_w-length(std_weekly)/b)**2/(length(std_weekly)/b)))
}

func(c(0.15,4))

res <- suppressWarnings(optim(par=c(0.1,4),fn=func,method="BFGS"))

#hist of optimal daily
alpha_opt_d=0.1212156
sigma_opt_d=4.1111241
mix_daily_opt_er = std_daily*sqrt((1-alpha_opt_d) + alpha_opt_d*sigma_opt_d**2)
r_mix_opt_er = (1-alpha_opt_d)*pnorm(mix_daily_opt_er) + alpha*pnorm(mix_daily_opt_er,sd=sigma_opt_d)
hist(r_mix_opt_er, breaks = 50, main = "Histogram of the optimal mixed normal distribution (2 components)",xlab = "q_it")
```
Nonetheless, as the parameters of the tested distribution are chosen arbitrarily, one should consider the best possible mixed distribution. Optimizing the mixed distribution with regard to the distribution parameters of the second component still yields the rejection of this being the true underlying distribution. Rosenblatt (1952) derived that the distribution of $q_{it} = \int_{- \infty }^{r_{it}} f(s) \,ds  = F(r_{it};\theta)$ under the null hypothesis is uniform. As Figure ??? shows and as the p-value of 0 confirms, the distribution of $q_it$ is clearly not uniform and even the optimized two-component mixed normal distribution is rejected as the true underlying distribution. The results for weekly returns are similar. While out of scope, one of several possible improvements of distribution fit could be the addition of components to the mixed distribution.

